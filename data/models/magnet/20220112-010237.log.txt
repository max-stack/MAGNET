2022-01-12 01:02:37,572 [INFO :__main__] My PID is 22148
2022-01-12 01:02:37,572 [INFO :__main__] PyTorch version: 1.10.0+cu102
2022-01-12 01:02:37,574 [INFO :__main__] Namespace(att_vec_size=512, batch_size=64, beam_size=3, brnn=True, brnn_merge='concat', cuda_seed=12345, curriculum=0, dec_rnn_size=512, dev_input_lda=None, dev_input_src='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/dev/dev.equ', dev_ref='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/dev/dev.nl', dropout=0.5, enc_rnn_size=512, epochs=20, eq_lambda=0.0, eval_per_batch=100, extra_shuffle=True, gpus=[0], halve_lr_bad_count=6, input_feed=1, layers=1, lda_vocab=None, learning_rate=0.001, learning_rate_decay=0.5, log_home='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/models/magnet', log_interval=100, loss_normalize=False, max_generator_batches=32, max_grad_norm=5, max_lda_words=10, max_sent_length=100, max_weight_value=15, maxout_pool_size=2, online_process_data=True, optim='adam', param_init=0.1, pre_word_vecs_dec=None, pre_word_vecs_enc=None, process_shuffle=False, save_path='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/models/magnet', seed=12345, src_vocab='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/train/vocab.equ.txt', start_decay_at=8, start_epoch=1, start_eval_batch=200, test_input_lda=None, test_input_src=None, test_ref=None, tgt_vocab='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/train/vocab.nl.txt', train_from='', train_from_state_dict='', train_lda=None, train_src='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/train/train.equ', train_tgt='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/train/train.nl', word_vec_size=300)
2022-01-12 01:02:37,601 [INFO :__main__] My seed is 12345
2022-01-12 01:02:37,602 [INFO :__main__] My cuda seed is 12345
2022-01-12 01:02:37,606 [INFO :onlinePreprocess] Reading source vocabulary from 'D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/train/vocab.equ.txt'...
