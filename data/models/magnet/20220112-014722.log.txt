2022-01-12 01:47:22,148 [INFO :__main__] My PID is 15820
2022-01-12 01:47:22,148 [INFO :__main__] PyTorch version: 1.10.0+cu102
2022-01-12 01:47:22,150 [INFO :__main__] Namespace(att_vec_size=512, batch_size=64, beam_size=3, brnn=True, brnn_merge='concat', cuda_seed=12345, curriculum=0, dec_rnn_size=512, dev_input_lda=None, dev_input_src=None, dev_ref=None, dropout=0.5, enc_rnn_size=512, epochs=20, eq_lambda=0.0, eval_per_batch=100, extra_shuffle=True, gpus=[0], halve_lr_bad_count=6, input_feed=1, layers=1, lda_vocab=None, learning_rate=0.001, learning_rate_decay=0.5, log_home='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/models/magnet', log_interval=100, loss_normalize=False, max_generator_batches=32, max_grad_norm=5, max_lda_words=10, max_sent_length=100, max_weight_value=15, maxout_pool_size=2, online_process_data=True, optim='adam', param_init=0.1, pre_word_vecs_dec=None, pre_word_vecs_enc=None, process_shuffle=False, save_path='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/models/magnet', seed=12345, src_vocab=None, start_decay_at=8, start_epoch=1, start_eval_batch=200, test_input_lda=None, test_input_src=None, test_ref=None, tgt_vocab=None, train_from='', train_from_state_dict='', train_lda='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/train/train.lda.txt', train_src='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/train/train.equ.txt', train_tgt='D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/train/train.nl.txt', word_vec_size=300)
2022-01-12 01:47:22,177 [INFO :__main__] My seed is 12345
2022-01-12 01:47:22,180 [INFO :__main__] My cuda seed is 12345
2022-01-12 01:47:22,187 [INFO :onlinePreprocess] Building source vocabulary...
2022-01-12 01:47:22,188 [INFO :onlinePreprocess] Created dictionary of size 4 (pruned from 12)
2022-01-12 01:47:22,189 [INFO :onlinePreprocess] Building target vocabulary...
2022-01-12 01:47:22,189 [INFO :onlinePreprocess] Created dictionary of size 4 (pruned from 22)
2022-01-12 01:47:22,190 [INFO :onlinePreprocess] Building lda vocabulary...
2022-01-12 01:47:22,191 [INFO :onlinePreprocess] Created dictionary of size 4 (pruned from 7)
2022-01-12 01:47:22,192 [INFO :onlinePreprocess] Preparing training ...
2022-01-12 01:47:22,193 [INFO :onlinePreprocess] Processing D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/train/train.equ.txt & D:/Documents/ComputerScienceYear3/PersonalProject/MAGNET/data/train/train.nl.txt ...
2022-01-12 01:47:22,194 [INFO :onlinePreprocess] ... sorting sentences by size
2022-01-12 01:47:22,195 [INFO :onlinePreprocess] Prepared 1 sentences (0 ignored due to length == 0 or > 100)
2022-01-12 01:47:22,196 [INFO :__main__]  * vocabulary size. source = 4; target = 4
2022-01-12 01:47:22,198 [INFO :__main__]  * number of training sentences. 1
2022-01-12 01:47:22,199 [INFO :__main__]  * maximum batch size. 64
2022-01-12 01:47:22,200 [INFO :__main__] Building model...
2022-01-12 01:47:24,594 [INFO :__main__] encoder.word_lut.weight
2022-01-12 01:47:24,594 [INFO :__main__] encoder.rnn.weight_ih_l0
2022-01-12 01:47:24,595 [INFO :__main__] encoder.rnn.weight_hh_l0
2022-01-12 01:47:24,596 [INFO :__main__] encoder.rnn.bias_ih_l0
2022-01-12 01:47:24,596 [INFO :__main__] encoder.rnn.bias_hh_l0
2022-01-12 01:47:24,597 [INFO :__main__] encoder.rnn.weight_ih_l0_reverse
2022-01-12 01:47:24,597 [INFO :__main__] encoder.rnn.weight_hh_l0_reverse
2022-01-12 01:47:24,598 [INFO :__main__] encoder.rnn.bias_ih_l0_reverse
2022-01-12 01:47:24,598 [INFO :__main__] encoder.rnn.bias_hh_l0_reverse
2022-01-12 01:47:24,599 [INFO :__main__] topic_encoder.word_lut.weight
2022-01-12 01:47:24,599 [INFO :__main__] decoder.word_lut.weight
2022-01-12 01:47:24,600 [INFO :__main__] decoder.rnn.layers.0.weight_ih
2022-01-12 01:47:24,600 [INFO :__main__] decoder.rnn.layers.0.weight_hh
2022-01-12 01:47:24,601 [INFO :__main__] decoder.rnn.layers.0.bias_ih
2022-01-12 01:47:24,602 [INFO :__main__] decoder.rnn.layers.0.bias_hh
2022-01-12 01:47:24,602 [INFO :__main__] decoder.attn.linear_pre.weight
2022-01-12 01:47:24,603 [INFO :__main__] decoder.attn.linear_pre.bias
2022-01-12 01:47:24,605 [INFO :__main__] decoder.attn.linear_q.weight
2022-01-12 01:47:24,606 [INFO :__main__] decoder.attn.linear_v.weight
2022-01-12 01:47:24,606 [INFO :__main__] decoder.topic_attn.linear_pre.weight
2022-01-12 01:47:24,607 [INFO :__main__] decoder.topic_attn.linear_pre.bias
2022-01-12 01:47:24,607 [INFO :__main__] decoder.topic_attn.linear_q.weight
2022-01-12 01:47:24,608 [INFO :__main__] decoder.topic_attn.linear_v.weight
2022-01-12 01:47:24,608 [INFO :__main__] decoder.readout.weight
2022-01-12 01:47:24,609 [INFO :__main__] decoder.readout.bias
2022-01-12 01:47:24,609 [INFO :__main__] decoder.mix_gate.weight
2022-01-12 01:47:24,609 [INFO :__main__] decoder.mix_gate.bias
2022-01-12 01:47:24,610 [INFO :__main__] decIniter.initer.weight
2022-01-12 01:47:24,610 [INFO :__main__] decIniter.initer.bias
2022-01-12 01:47:24,611 [INFO :__main__] generator.0.weight
2022-01-12 01:47:24,611 [INFO :__main__] generator.0.bias
